#!/usr/bin/env python3
"""
Usage example for garak_prompt_injection.py

This script demonstrates how to use the Garak Prompt Injection Testing Tool
"""

def print_usage_example():
    """Print a comprehensive usage example"""
    
    print("""
üöÄ Garak Prompt Injection Testing Tool - Usage Example
=====================================================

This script helps you test LLM models for prompt injection vulnerabilities using NVIDIA's garak tool.

üìã Prerequisites:
================
1. Miniconda or Anaconda installed
2. Ollama installed and running
3. Either a .gguf model file or an existing Ollama model

üîß Setup Instructions:
====================

1. Install Miniconda (if not already installed):
   wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh
   bash Miniconda3-latest-Linux-x86_64.sh

2. Install Ollama (if not already installed):
   curl -fsSL https://ollama.ai/install.sh | sh

3. If using .gguf model, have your model file ready:
   - Example: /path/to/your/model.gguf

4. If using existing Ollama model, pull it first:
   ollama pull llama3.1:8b
   ollama pull mistral-nemo:latest

üéØ Running the Tool:
==================
python garak_prompt_injection.py

üìä Available Test Probes:
========================
‚Ä¢ garak.probes.promptinject - Primary prompt injection tests
‚Ä¢ garak.probes.dan - "Do Anything Now" jailbreak attempts
‚Ä¢ garak.probes.encoding - Encoding-based injection tests
‚Ä¢ garak.probes.latentinjection - Hidden injection tests
‚Ä¢ garak.probes.exploitation - Code and template injection
‚Ä¢ garak.probes.malwaregen - Malware generation attempts
‚Ä¢ garak.probes.xss - Cross-site scripting tests
‚Ä¢ garak.probes.grandma - Social engineering tests
‚Ä¢ garak.probes.doctor - Professional role exploitation
‚Ä¢ ...and 24 more specialized probes

üí° Pro Tips:
============
‚Ä¢ Start with 'garak.probes.promptinject' for basic testing
‚Ä¢ Use 'all' to run comprehensive security testing
‚Ä¢ Tests can take several minutes to complete
‚Ä¢ Reports are automatically opened in your browser
‚Ä¢ Results are saved in ~/.garak/ directory

üîç Example Test Scenarios:
==========================

Scenario 1: Testing a downloaded .gguf model
1. Choose option 1 (LLM model in .gguf format)
2. Provide path to your .gguf file
3. Give your model a name
4. Choose option 1 to create environment
5. Select probes (recommend: promptinject, dan, encoding)
6. Wait for results

Scenario 2: Testing an existing Ollama model
1. Choose option 2 (Already pulled model in Ollama)
2. Select from available models
3. Choose option 2 if environment already exists
4. Select probes for testing
5. Review results

üõ°Ô∏è Security Best Practices:
===========================
‚Ä¢ Run tests in isolated environments
‚Ä¢ Don't use production models for testing
‚Ä¢ Review results with security experts
‚Ä¢ Keep test data non-sensitive
‚Ä¢ Regular testing for model updates

üìà Understanding Results:
========================
‚Ä¢ Green ‚úì: Test passed (model is secure)
‚Ä¢ Red ‚úó: Test failed (potential vulnerability)
‚Ä¢ Yellow ‚ö†: Warning or attention needed
‚Ä¢ Reports show attack success rates
‚Ä¢ HTML reports provide detailed analysis

üÜò Troubleshooting:
==================
‚Ä¢ "Conda not found": Add conda to PATH
‚Ä¢ "Ollama not found": Install Ollama
‚Ä¢ "Model creation failed": Check file permissions
‚Ä¢ "Garak installation failed": Check internet connection

Ready to test your LLM's security? Run the script and follow the prompts!
""")

if __name__ == "__main__":
    print_usage_example()